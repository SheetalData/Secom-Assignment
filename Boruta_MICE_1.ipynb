{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5515c5df-6749-4f3c-805a-c867bd3d25de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature1  feature2   feature3   feature4  feature5  feature6  feature7  \\\n",
      "0      3030.93   2564.00  2187.7333  1411.1265    1.3602     100.0   97.6133   \n",
      "1      3095.78   2465.14  2230.4222  1463.6606    0.8294     100.0  102.3433   \n",
      "2      2932.61   2559.94  2186.4111  1698.0172    1.5102     100.0   95.4878   \n",
      "3      2988.72   2479.90  2199.0333   909.7926    1.3204     100.0  104.2367   \n",
      "4      3032.24   2502.87  2233.3667  1326.5200    1.5334     100.0  100.3967   \n",
      "...        ...       ...        ...        ...       ...       ...       ...   \n",
      "1562   2899.41   2464.36  2179.7333  3085.3781    1.4843     100.0   82.2467   \n",
      "1563   3052.31   2522.55  2198.5667  1124.6595    0.8763     100.0   98.4689   \n",
      "1564   2978.81   2379.78  2206.3000  1110.4967    0.8236     100.0   99.4122   \n",
      "1565   2894.92   2532.01  2177.0333  1183.7287    1.5726     100.0   98.7978   \n",
      "1566   2944.92   2450.76  2195.4444  2914.1792    1.5978     100.0   85.1011   \n",
      "\n",
      "      feature8  feature9  feature10  ...  feature583  feature584  feature585  \\\n",
      "0       0.1242    1.5005     0.0162  ...      0.5005      0.0118      0.0035   \n",
      "1       0.1247    1.4966    -0.0005  ...      0.5019      0.0223      0.0055   \n",
      "2       0.1241    1.4436     0.0041  ...      0.4958      0.0157      0.0039   \n",
      "3       0.1217    1.4882    -0.0124  ...      0.4990      0.0103      0.0025   \n",
      "4       0.1235    1.5031    -0.0031  ...      0.4800      0.4766      0.1045   \n",
      "...        ...       ...        ...  ...         ...         ...         ...   \n",
      "1562    0.1248    1.3424    -0.0045  ...      0.4988      0.0143      0.0039   \n",
      "1563    0.1205    1.4333    -0.0061  ...      0.4975      0.0131      0.0036   \n",
      "1564    0.1208       NaN        NaN  ...      0.4987      0.0153      0.0041   \n",
      "1565    0.1213    1.4622    -0.0072  ...      0.5004      0.0178      0.0038   \n",
      "1566    0.1235       NaN        NaN  ...      0.4987      0.0181      0.0040   \n",
      "\n",
      "      feature586  feature587  feature588  feature589  feature590  Result  \\\n",
      "0         2.3630         NaN         NaN         NaN         NaN      -1   \n",
      "1         4.4447      0.0096      0.0201      0.0060    208.2045      -1   \n",
      "2         3.1745      0.0584      0.0484      0.0148     82.8602       1   \n",
      "3         2.0544      0.0202      0.0149      0.0044     73.8432      -1   \n",
      "4        99.3032      0.0202      0.0149      0.0044     73.8432      -1   \n",
      "...          ...         ...         ...         ...         ...     ...   \n",
      "1562      2.8669      0.0068      0.0138      0.0047    203.1720      -1   \n",
      "1563      2.6238      0.0068      0.0138      0.0047    203.1720      -1   \n",
      "1564      3.0590      0.0197      0.0086      0.0025     43.5231      -1   \n",
      "1565      3.5662      0.0262      0.0245      0.0075     93.4941      -1   \n",
      "1566      3.6275      0.0117      0.0162      0.0045    137.7844      -1   \n",
      "\n",
      "                    Date  \n",
      "0    2008-07-19 11:55:00  \n",
      "1    2008-07-19 12:32:00  \n",
      "2    2008-07-19 13:17:00  \n",
      "3    2008-07-19 14:43:00  \n",
      "4    2008-07-19 15:22:00  \n",
      "...                  ...  \n",
      "1562 2008-10-16 15:13:00  \n",
      "1563 2008-10-16 20:49:00  \n",
      "1564 2008-10-17 05:26:00  \n",
      "1565 2008-10-17 06:01:00  \n",
      "1566 2008-10-17 06:07:00  \n",
      "\n",
      "[1567 rows x 592 columns]\n",
      "shape of x: (1567, 590)\n",
      "shape of y: (1567, 1)\n",
      "shape of x_train:  (1096, 590)\n",
      "shape of x_test:  (471, 590)\n",
      "shape of y_train:  (1096, 1)\n",
      "shape of y_test:  (471, 1)\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import shapiro\n",
    "# imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "url1 ='https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data'\n",
    "names = [\"feature\" + str(x) for x in range(1, 591)]\n",
    "df1 = pd.read_csv(url1,sep=\" \", names=names, na_values = \"NaN\",header=None)\n",
    "df1.head()\n",
    "\n",
    "url2 ='https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom_labels.data'\n",
    "df2 = pd.read_csv(url2,sep=\" \",names = [\"Result\",\"Date\"])\n",
    "\n",
    "#df2.columns =['Pass/Fail','Date']\n",
    "df2.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Convertion of Date into Datetime from Object(String) data types\n",
    "df2['Date'] = pd.to_datetime(df2['Date'])\n",
    "df2.dtypes\n",
    "\n",
    "\n",
    "\n",
    "#Joinig TWO df1 and df2 Dataframe naming SECOM\n",
    "Secom = pd.concat([df1,df2],axis = 1)\n",
    "print(Secom)\n",
    "\n",
    "Secom = Secom.drop(['Date'],axis=1)\n",
    "                   \n",
    "# establish target and features of the manufacturing data\n",
    "# set the target to the encoded manufacturing outcome column\n",
    "y = Secom[['Result']]\n",
    "# set the features as the rest of the dataset after dropping the features that are no\n",
    "x = Secom.drop(['Result'], axis=1)\n",
    "\n",
    "# getting the shapes of new data sets x and y\n",
    "print(\"shape of x:\", x.shape)\n",
    "print(\"shape of y:\", y.shape)\n",
    "\n",
    "#Splitting data\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 1,stratify = y)\n",
    "\n",
    "\n",
    "\n",
    "# getting the counts\n",
    "print(\"shape of x_train: \", x_train.shape)\n",
    "print(\"shape of x_test: \", x_test.shape)\n",
    "print(\"shape of y_train: \", y_train.shape)\n",
    "print(\"shape of y_test: \", y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Removing features having Missing ratio more than 50%\n",
    "\n",
    "\n",
    "def percentna(dataframe, threshold):\n",
    "    columns = dataframe.columns[(dataframe.isnull().sum()/len(dataframe))>threshold]\n",
    "    return columns.tolist()\n",
    "\n",
    " \n",
    "\n",
    "na_columns = percentna(x_train, 0.5)\n",
    "len(na_columns)\n",
    "x_train_dn = x_train.drop(na_columns, axis=1)\n",
    "x_train_dn.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Low Variance Filter\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "var_thres=VarianceThreshold(threshold=0)\n",
    "var_thres.fit(x_train_dn)\n",
    "\n",
    " \n",
    "\n",
    "constant_columns = [column for column in x_train_dn.columns\n",
    "                    if column not in x_train_dn.columns[var_thres.get_support()]]\n",
    "\n",
    "\n",
    "print(len(constant_columns))\n",
    "\n",
    "x_train_lv = x_train_dn.drop(constant_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b68c69f5-da55-41e1-8d93-ae65036abdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(feat):\n",
    " upper_limit = feat.mean() + 3*feat.std()\n",
    " lower_limit = feat.mean() - 3*feat.std()\n",
    "\n",
    " feat = np.where(\n",
    "    feat >upper_limit,\n",
    "    upper_limit,\n",
    "    np.where(\n",
    "       feat <lower_limit,\n",
    "        lower_limit,\n",
    "        feat ))\n",
    " return feat\n",
    "\n",
    "x_train_outliers_imputation =x_train_lv.copy()\n",
    "for column in x_train_outliers_imputation:\n",
    "  x_train_outliers_imputation[column] = outliers(x_train_outliers_imputation[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccb70cd7-77dd-469a-9c47-867ffc0b3861",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\MPMD\\SEM 2\\eMPMD_2.2_Advanced_Data_Analytics\\00 Assignment\\Secom-Assignment-1\\Secom-Assignment-1\\Boruta_MICE_1.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MPMD/SEM%202/eMPMD_2.2_Advanced_Data_Analytics/00%20Assignment/Secom-Assignment-1/Secom-Assignment-1/Boruta_MICE_1.ipynb#ch0000002?line=2'>3</a>\u001b[0m \u001b[39m# start the MICE training\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MPMD/SEM%202/eMPMD_2.2_Advanced_Data_Analytics/00%20Assignment/Secom-Assignment-1/Secom-Assignment-1/Boruta_MICE_1.ipynb#ch0000002?line=3'>4</a>\u001b[0m imputed_training\u001b[39m=\u001b[39mmice(x_train_outliers_imputation\u001b[39m.\u001b[39mvalues)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/MPMD/SEM%202/eMPMD_2.2_Advanced_Data_Analytics/00%20Assignment/Secom-Assignment-1/Secom-Assignment-1/Boruta_MICE_1.ipynb#ch0000002?line=4'>5</a>\u001b[0m imputed_test\u001b[39m=\u001b[39mmice(x_test\u001b[39m.\u001b[39;49mvalues)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MPMD/SEM%202/eMPMD_2.2_Advanced_Data_Analytics/00%20Assignment/Secom-Assignment-1/Secom-Assignment-1/Boruta_MICE_1.ipynb#ch0000002?line=6'>7</a>\u001b[0m array_sum_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(imputed_training)\u001b[39m#https://www.adamsmith.haus/python/answers/how-to-check-for-nan-elements-in-a-numpy-array-in-python\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MPMD/SEM%202/eMPMD_2.2_Advanced_Data_Analytics/00%20Assignment/Secom-Assignment-1/Secom-Assignment-1/Boruta_MICE_1.ipynb#ch0000002?line=7'>8</a>\u001b[0m array_sum_test \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(imputed_test) \n",
      "File \u001b[1;32mc:\\Users\\divya\\anaconda3\\lib\\site-packages\\impyute\\util\\preprocess.py:55\u001b[0m, in \u001b[0;36mpreprocess.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[39mreturn\u001b[39;00m pd_DataFrame(fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n\u001b[0;32m     54\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 55\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\divya\\anaconda3\\lib\\site-packages\\impyute\\util\\checks.py:36\u001b[0m, in \u001b[0;36mchecks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m _nan_exists(data):\n\u001b[0;32m     35\u001b[0m     \u001b[39mraise\u001b[39;00m BadInputError(\u001b[39m\"\u001b[39m\u001b[39mNo NaN\u001b[39m\u001b[39m'\u001b[39m\u001b[39ms in given data\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\divya\\anaconda3\\lib\\site-packages\\impyute\\imputation\\cs\\mice.py:70\u001b[0m, in \u001b[0;36mmice\u001b[1;34m(data, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m     y_train\u001b[39m.\u001b[39mappend(data[x_i][dependent_col])\n\u001b[0;32m     69\u001b[0m model \u001b[39m=\u001b[39m LinearRegression()\n\u001b[1;32m---> 70\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train)\n\u001b[0;32m     72\u001b[0m \u001b[39m# Step 4: Missing values for the missing variable/column are replaced\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39m# with predictions from our new linear regression model\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[39m# For null indices with the dependent column that was randomly chosen\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m i, z \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(null_xyv):\n",
      "File \u001b[1;32mc:\\Users\\divya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:718\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_residues \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack([out[\u001b[39m3\u001b[39m] \u001b[39mfor\u001b[39;00m out \u001b[39min\u001b[39;00m outs])\n\u001b[0;32m    717\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 718\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_residues, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrank_, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msingular_ \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39;49mlstsq(X, y)\n\u001b[0;32m    719\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT\n\u001b[0;32m    721\u001b[0m \u001b[39mif\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\divya\\anaconda3\\lib\\site-packages\\scipy\\linalg\\basic.py:1204\u001b[0m, in \u001b[0;36mlstsq\u001b[1;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001b[0m\n\u001b[0;32m   1202\u001b[0m \u001b[39mif\u001b[39;00m real_data:\n\u001b[0;32m   1203\u001b[0m     lwork, iwork \u001b[39m=\u001b[39m _compute_lwork(lapack_lwork, m, n, nrhs, cond)\n\u001b[1;32m-> 1204\u001b[0m     x, s, rank, info \u001b[39m=\u001b[39m lapack_func(a1, b1, lwork,\n\u001b[0;32m   1205\u001b[0m                                    iwork, cond, \u001b[39mFalse\u001b[39;00m, \u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1206\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# complex data\u001b[39;00m\n\u001b[0;32m   1207\u001b[0m     lwork, rwork, iwork \u001b[39m=\u001b[39m _compute_lwork(lapack_lwork, m, n,\n\u001b[0;32m   1208\u001b[0m                                          nrhs, cond)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from impyute.imputation.cs import mice\n",
    "\n",
    "# start the MICE training\n",
    "imputed_training=mice(x_train_outliers_imputation.values)\n",
    "imputed_test=mice(x_test.values)\n",
    "\n",
    "array_sum_train = np.sum(imputed_training)#https://www.adamsmith.haus/python/answers/how-to-check-for-nan-elements-in-a-numpy-array-in-python\n",
    "array_sum_test = np.sum(imputed_test) \n",
    "Trainset = np.isnan(array_sum_train)\n",
    "Testset = np.isnan(array_sum_test)\n",
    "\n",
    "Trainset\n",
    "Testset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13ea241",
   "metadata": {},
   "source": [
    "#### Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbc38c4-2426-4e94-a7e0-b679fa032624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BORUTA\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=1, n_estimators=1000, max_depth=5)\n",
    "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, random_state=1)\n",
    "boruta_selector.fit(np.array(imputed_training), np.array(y_train)) \n",
    "\n",
    "\n",
    "# Ranking of Boruta\n",
    "\n",
    "print(\"Ranking: \",boruta_selector.ranking_)          \n",
    "print(\"No. of significant features: \", boruta_selector.n_features_) \n",
    "\n",
    "\n",
    "\n",
    "selected_rf_features = pd.DataFrame({'Feature':list(imputed_training.columns),\n",
    "                                       'Ranking':boruta_selector.ranking_})\n",
    "selected_rf_features.sort_values(by='Ranking').head(30)\n",
    "\n",
    "\n",
    "# Using the BorutaPy object to transform the features in the dataset.\n",
    "\n",
    "X_Filtered_train = boruta_selector.transform(np.array(imputed_training))\n",
    "\n",
    "X_Filtered_test = boruta_selector.transform(np.array(imputed_test)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9daabcc",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a7257",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\MPMD\\SEM 2\\eMPMD_2.2_Advanced_Data_Analytics\\00 Assignment\\Secom-Assignment-1\\Secom-Assignment-1\\Boruta_MICE_1.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MPMD/SEM%202/eMPMD_2.2_Advanced_Data_Analytics/00%20Assignment/Secom-Assignment-1/Secom-Assignment-1/Boruta_MICE_1.ipynb#ch0000008?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MPMD/SEM%202/eMPMD_2.2_Advanced_Data_Analytics/00%20Assignment/Secom-Assignment-1/Secom-Assignment-1/Boruta_MICE_1.ipynb#ch0000008?line=1'>2</a>\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/MPMD/SEM%202/eMPMD_2.2_Advanced_Data_Analytics/00%20Assignment/Secom-Assignment-1/Secom-Assignment-1/Boruta_MICE_1.ipynb#ch0000008?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtree\u001b[39;00m \u001b[39mimport\u001b[39;00m DecisionTreeClassifier\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MPMD/SEM%202/eMPMD_2.2_Advanced_Data_Analytics/00%20Assignment/Secom-Assignment-1/Secom-Assignment-1/Boruta_MICE_1.ipynb#ch0000008?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/MPMD/SEM%202/eMPMD_2.2_Advanced_Data_Analytics/00%20Assignment/Secom-Assignment-1/Secom-Assignment-1/Boruta_MICE_1.ipynb#ch0000008?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnaive_bayes\u001b[39;00m \u001b[39mimport\u001b[39;00m GaussianNB\n",
      "File \u001b[1;32mc:\\Users\\divya\\anaconda3\\lib\\site-packages\\sklearn\\__init__.py:82\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _distributor_init  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __check_build  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m---> 82\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m clone\n\u001b[0;32m     83\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_show_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n\u001b[0;32m     85\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[0;32m     86\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcalibration\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     87\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mshow_versions\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    129\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\divya\\anaconda3\\lib\\site-packages\\sklearn\\base.py:17\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config\n\u001b[1;32m---> 17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _IS_32BIT\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_tags\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     _DEFAULT_TAGS,\n\u001b[0;32m     20\u001b[0m     _safe_tags,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m check_X_y\n",
      "File \u001b[1;32mc:\\Users\\divya\\anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py:28\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m DataConversionWarning\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdeprecation\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecated\n\u001b[1;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfixes\u001b[39;00m \u001b[39mimport\u001b[39;00m np_version, parse_version\n\u001b[0;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_estimator_html_repr\u001b[39;00m \u001b[39mimport\u001b[39;00m estimator_html_repr\n\u001b[0;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     31\u001b[0m     as_float_array,\n\u001b[0;32m     32\u001b[0m     assert_all_finite,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m     check_scalar,\n\u001b[0;32m     41\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\divya\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:20\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msp\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinalg\u001b[39;00m \u001b[39mimport\u001b[39;00m lsqr \u001b[39mas\u001b[39;00m sparse_lsqr  \u001b[39m# noqa\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mthreadpoolctl\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\divya\\anaconda3\\lib\\site-packages\\scipy\\stats\\__init__.py:441\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    438\u001b[0m \n\u001b[0;32m    439\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 441\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    442\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdistributions\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m    443\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmorestats\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\divya\\anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py:37\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mimport\u001b[39;00m array, asarray, ma\n\u001b[1;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspatial\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdistance\u001b[39;00m \u001b[39mimport\u001b[39;00m cdist\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mndimage\u001b[39;00m \u001b[39mimport\u001b[39;00m measurements\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_lib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_util\u001b[39;00m \u001b[39mimport\u001b[39;00m (check_random_state, MapWrapper,\n\u001b[0;32m     40\u001b[0m                               rng_integers, float_factorial)\n",
      "File \u001b[1;32mc:\\Users\\divya\\anaconda3\\lib\\site-packages\\scipy\\spatial\\__init__.py:107\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    104\u001b[0m __all__ \u001b[39m=\u001b[39m [s \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mdir\u001b[39m() \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m s\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m)]\n\u001b[0;32m    105\u001b[0m __all__ \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mdistance\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtransform\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m--> 107\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m distance, transform\n\u001b[0;32m    109\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_lib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_testutils\u001b[39;00m \u001b[39mimport\u001b[39;00m PytestTester\n\u001b[0;32m    110\u001b[0m test \u001b[39m=\u001b[39m PytestTester(\u001b[39m__name__\u001b[39m)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:971\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:914\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1407\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1379\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1506\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:142\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "#from sklearn.metrics import scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "classifiers = [['RandomForest :',RandomForestClassifier()]]\n",
    "\n",
    "for name,classifier in classifiers:\n",
    "    clf=classifier.fit(X_Filtered_train,y_train)\n",
    "    y_pred=classifier.predict(X_Filtered_test)\n",
    "    print(f'\\n {name} \\n')\n",
    "    print(f'Training Score for {name}  {clf.score(X_Filtered_train,y_train) * 100:.2f}' )\n",
    "    print(f'Testing Score for {name} {clf.score(X_Filtered_test,y_test) * 100:.2f}' )\n",
    "    print(f'Classification report  \\n {classification_report(y_test,y_pred)}' )\n",
    "    print(f'Confusion matrix  \\n {confusion_matrix(y_test,y_pred)}' )\n",
    "    print(f'ROC AUC  : {roc_auc_score(y_test,y_pred)}' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "44df468d23e9f8c56622276b10134b0e97e2035b13bfe87941709e3f27b73c34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
