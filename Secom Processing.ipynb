{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e2e26c-cf06-4ca5-83ee-d154a87dcc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import missingno as msno\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import shapiro\n",
    "# imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "url1 ='https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data'\n",
    "names = [\"feature\" + str(x) for x in range(1, 591)]\n",
    "df1 = pd.read_csv(url1,sep=\" \", names=names, na_values = \"NaN\",header=None)\n",
    "df1.head()\n",
    "\n",
    "url2 ='https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom_labels.data'\n",
    "df2 = pd.read_csv(url2,sep=\" \",names = [\"Result\",\"Date\"])\n",
    "\n",
    "#df2.columns =['Pass/Fail','Date']\n",
    "df2.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Convertion of Date into Datetime from Object(String) data types\n",
    "df2['Date'] = pd.to_datetime(df2['Date'])\n",
    "df2.dtypes\n",
    "\n",
    "\n",
    "\n",
    "#Joinig TWO df1 and df2 Dataframe naming SECOM\n",
    "Secom = pd.concat([df1,df2],axis = 1)\n",
    "print(Secom)\n",
    "\n",
    "Secom = Secom.drop(['Date']\n",
    "                   \n",
    "# establish target and features of the manufacturing data\n",
    "# set the target to the encoded manufacturing outcome column\n",
    "y = Secom[['Result']]\n",
    "# set the features as the rest of the dataset after dropping the features that are no\n",
    "x = Secom.drop(['Result'], axis=1)\n",
    "\n",
    "# getting the shapes of new data sets x and y\n",
    "print(\"shape of x:\", x.shape)\n",
    "print(\"shape of y:\", y.shape)\n",
    "\n",
    "#Splitting data\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 1,stratify = y)\n",
    "\n",
    "\n",
    "\n",
    "# getting the counts\n",
    "print(\"shape of x_train: \", x_train.shape)\n",
    "print(\"shape of x_test: \", x_test.shape)\n",
    "print(\"shape of y_train: \", y_train.shape)\n",
    "print(\"shape of y_test: \", y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Removing features having Missing ratio more than 50%\n",
    "\n",
    "\n",
    "def percentna(dataframe, threshold):\n",
    "    columns = dataframe.columns[(dataframe.isnull().sum()/len(dataframe))>threshold]\n",
    "    return columns.tolist()\n",
    "\n",
    " \n",
    "\n",
    "na_columns = percentna(x_train, 0.5)\n",
    "len(na_columns)\n",
    "x_train_dn = x_train.drop(na_columns, axis=1)\n",
    "x_train_dn.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Low Variance Filter\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "var_thres=VarianceThreshold(threshold=0)\n",
    "var_thres.fit(x_train_dn)\n",
    "\n",
    " \n",
    "\n",
    "constant_columns = [column for column in x_train_dn.columns\n",
    "                    if column not in x_train_dn.columns[var_thres.get_support()]]\n",
    "\n",
    "\n",
    "print(len(constant_columns))\n",
    "\n",
    "x_train_lv = x_train_dn.drop(constant_columns,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70f5c2f-63e9-4c4d-ba0f-be8a2b0c3249",
   "metadata": {},
   "source": [
    "## Outlier Method 1 - By Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9550b9-6202-4d2f-bb2b-3dfc0e4e0163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(feat):\n",
    " upper_limit = feat.mean() + 3*feat.std()\n",
    " lower_limit = feat.mean() - 3*feat.std()\n",
    "\n",
    " feat = np.where(\n",
    "    feat >upper_limit,\n",
    "    upper_limit,\n",
    "    np.where(\n",
    "       feat <lower_limit,\n",
    "        lower_limit,\n",
    "        feat ))\n",
    " return feat\n",
    "\n",
    "x_train_outliers_imputation =x_train_lv.copy()\n",
    "for column in x_train_outliers_imputation:\n",
    "  x_train_outliers_imputation[column] = outliers(x_train_outliers_imputation[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815f47c8-f0e6-4e0a-9930-65adc99ac86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_outliers_imputation.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7d1e7b-5e23-4ae0-9407-36b3ac73ab5a",
   "metadata": {},
   "source": [
    "## Outlier Method 2 - By QuantileTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d7403d-138e-4c94-b592-7ddf01c0c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IQR_outliers(data,limit=1.5):\n",
    "    numColumns = data.select_dtypes(include=np.number).columns.tolist(); # extract list of numeric columns\n",
    "    Q1 = data.quantile(0.25)\n",
    "    Q3 = data.quantile(0.75)\n",
    "    IQR = Q3-Q1;\n",
    "    outliers=((data[numColumns] < (Q1 - limit*IQR)) | (data[numColumns] > (Q3 + limit*IQR))).sum()*100/data.shape[0]\n",
    "    return outliers \n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "x_train_lv = x_train_lv.copy()\n",
    "quantile_transformer = QuantileTransformer(output_distribution='normal', random_state= 42)\n",
    "df_outliers = pd.DataFrame(quantile_transformer.fit_transform(x_train_lv),columns=x_train_lv.columns)\n",
    "outliers = IQR_outliers(df_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0abeeab-f6b8-44e7-af2c-cb5d4909bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers.plot(kind='box', subplots=True,layout=(120,5), fontsize=10, figsize=(15,150));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa69137d-783d-4628-9243-e173b8e933f9",
   "metadata": {},
   "source": [
    "## Missing Value Imputation Method 1- Mean "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b57bac6-f1fc-4e4c-b93c-12b3529f61c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1. Using Outlier Imputation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9ec849-6d02-4dd7-bbc5-026f0149aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "numColumns = x_train_outliers_imputation.select_dtypes(include=np.number).columns.tolist();\n",
    "\n",
    "# initialize imputer. use strategy='mean' for mean imputation\n",
    "imputer = SimpleImputer(strategy='mean')# fit the imputer on X_train. we pass only numeric columns with NA's here.\n",
    "imputer.fit(x_train_outliers_imputation[numColumns])# transform the data using the fitted imputer\n",
    "X_train_mean_impute = imputer.transform(x_train_outliers_imputation[numColumns])\n",
    "X_test_mean_impute = imputer.transform(x_test[numColumns])# put the output into DataFrame. remember to pass columns used in fit/transform\n",
    "X_train_mean_impute = pd.DataFrame(X_train_mean_impute, columns=numColumns)\n",
    "X_test_mean_impute = pd.DataFrame(X_test_mean_impute, columns=numColumns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c30a749-614c-4895-9d3d-54c0217b7b33",
   "metadata": {},
   "source": [
    "#### Accuracy Check for Missing Value Imputation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d663d3c-aa78-413b-8e11-94136bffadc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "#from sklearn.metrics import scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "classifiers = [['RandomForest :',RandomForestClassifier()]]\n",
    "\n",
    "\n",
    "for name,classifier in classifiers:\n",
    "    clf=classifier.fit(X_train_mean_impute,y_train)\n",
    "    y_pred=classifier.predict(X_test_mean_impute)\n",
    "    print(f'\\n {name} \\n')\n",
    "    print(f'Training Score for {name}  {clf.score(X_train_mean_impute,y_train) * 100:.2f}' )\n",
    "    print(f'Testing Score for {name} {clf.score(X_test_mean_impute,y_test) * 100:.2f}' )\n",
    "    print(f'Classification report  \\n {classification_report(y_test,y_pred)}' )\n",
    "    print(f'Confusion matrix  \\n {confusion_matrix(y_test,y_pred)}' )\n",
    "    print(f'ROC AUC  : {roc_auc_score(y_test,y_pred)}' )\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fdaed6-866f-4d80-ac56-775e7126f1f1",
   "metadata": {},
   "source": [
    "#### 2. Using Outlier Transformer dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9a29f7-4c25-41b2-b7f0-e6afb10be40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numColumns = df_outliers.select_dtypes(include=np.number).columns.tolist();\n",
    "\n",
    "# initialize imputer. use strategy='mean' for mean imputation\n",
    "imputer = SimpleImputer(strategy='mean')# fit the imputer on X_train. we pass only numeric columns with NA's here.\n",
    "imputer.fit(df_outliers[numColumns])# transform the data using the fitted imputer\n",
    "X_train_mean_impute = imputer.transform(df_outliers[numColumns])\n",
    "X_test_mean_impute = imputer.transform(x_test[numColumns])# put the output into DataFrame. remember to pass columns used in fit/transform\n",
    "X_train_mean_impute = pd.DataFrame(X_train_mean_impute, columns=numColumns)\n",
    "X_test_mean_impute = pd.DataFrame(X_test_mean_impute, columns=numColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799dbac9-f8bc-4dc3-a883-563540cfb001",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing Value Imputation Method 2- KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4814491d-9b56-456b-a57b-76d6f43d4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1.By Using Outlier Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d893a23-ea0e-4541-9f2a-872e811e3637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize imputer\n",
    "imputer = KNNImputer()\n",
    "\n",
    "\n",
    "\n",
    "# fit the imputer on X_train. pass only numeric columns.\n",
    "imputer.fit(x_train_outliers_imputation[numColumns])\n",
    "\n",
    "\n",
    "\n",
    "# transform the data using the fitted imputer\n",
    "X_train_knn_impute1 = imputer.transform(x_train_outliers_imputation[numColumns])\n",
    "X_test_knn_impute1 = imputer.transform(x_test[numColumns])\n",
    "\n",
    "\n",
    "\n",
    "# put the output into DataFrame. remember to pass columns used in fit/transform\n",
    "X_train_knn_impute1 = pd.DataFrame(X_train_knn_impute1, columns=numColumns)\n",
    "X_test_knn_impute1 = imputer.transform(x_test[numColumns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151cb3d5-20c9-4aa2-a5c4-c7bf0890620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2.By Using Outlier Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d979892-6dba-429e-8c37-5aa7a2848706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize imputer\n",
    "imputer = KNNImputer()\n",
    "\n",
    "\n",
    "\n",
    "# fit the imputer on X_train. pass only numeric columns.\n",
    "imputer.fit(df_outliers[numColumns])\n",
    "\n",
    "\n",
    "\n",
    "# transform the data using the fitted imputer\n",
    "X_train_knn_impute2 = imputer.transform(df_outliers[numColumns])\n",
    "X_test_knn_impute2 = imputer.transform(x_test[numColumns])\n",
    "\n",
    "\n",
    "\n",
    "# put the output into DataFrame. remember to pass columns used in fit/transform\n",
    "X_train_knn_impute2 = pd.DataFrame(df_outliers, columns=numColumns)\n",
    "X_test_knn_impute2 = imputer.transform(x_test[numColumns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c639a-636a-4b2d-9ce0-e2747ca09589",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing Value Imputation Method 3- Hotdeck "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab9a26d-ebc6-4cdb-a805-3afd0ba4b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1.By Using Outlier Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf93ccd-7d9c-4f2c-a76b-712706441052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hot deck (LOCF - last observation carried forward )\n",
    "\n",
    "x_train_Hot_deck1 = x_train_outliers_imputation.copy()\n",
    "\n",
    "x_train_Hot_deck1[num_cols_with_na] = x_train_Hot_deck1[num_cols_with_na].fillna(method ='ffill')\n",
    "\n",
    "\n",
    "num_cols_with_na = num_cols[x_train_Hot_deck1[num_cols].isnull().mean() > 0]\n",
    "print(f\"*** numerical columns that have NaN's ({len(num_cols_with_na)}): \\n{num_cols_with_na}\\n\\n\")\n",
    "\n",
    "\n",
    "x_train_Hot_deck1.isnull().mean().sort_values(ascending =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb20f98-f7f1-4fcf-aa47-bf49b4cf84d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2.By Using Outlier Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923b51d6-fab6-4bae-be4e-09ec9526285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hot deck (LOCF - last observation carried forward )\n",
    "\n",
    "x_train_Hot_deck2 = df_outliers.copy()\n",
    "\n",
    "x_train_Hot_deck2[num_cols_with_na] = x_train_Hot_deck2[num_cols_with_na].fillna(method ='ffill')\n",
    "\n",
    "\n",
    "num_cols_with_na = num_cols[x_train_Hot_deck2[num_cols].isnull().mean() > 0]\n",
    "print(f\"*** numerical columns that have NaN's ({len(num_cols_with_na)}): \\n{num_cols_with_na}\\n\\n\")\n",
    "\n",
    "\n",
    "x_train_Hot_deck2.isnull().mean().sort_values(ascending =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5418682b-22ca-4095-b869-53ed5ac81881",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing Value Imputation Method 4- Latest Fill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82e3c6d-9934-4af9-b369-e2659fdb1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1.By Using Outlier Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701a4819-6577-449e-9d94-b5bffd170d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest information available\n",
    "x_train_LastFill1 = x_train_outliers_imputation.copy()\n",
    "x_train_LastFill1.fillna(method='ffill', inplace=True)\n",
    "x_train_LastFill1.fillna(method='bfill', inplace=True)\n",
    "x_train_LastFill1\n",
    "\n",
    "x_train_LastFill1.isna().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe8250-589e-47fb-8bea-d1976d8fa54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2.By Using Outlier Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a8332-1f28-4109-889c-e52bf7ff35f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest information available\n",
    "x_train_LastFill2 = df_outliers.copy()\n",
    "x_train_LastFill2.fillna(method='ffill', inplace=True)\n",
    "x_train_LastFill2.fillna(method='bfill', inplace=True)\n",
    "x_train_LastFill2\n",
    "\n",
    "x_train_LastFill2.isna().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fde57e-e94b-4a1e-86ac-4c2451ac644b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing Value Imputation Method 5- MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cfcff4-5417-4008-8228-8fa6e6811594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 1.By Using Outlier Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae412b82-c8be-4c6e-8bd3-5b3b581fbaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from impyute.imputation.cs import mice\n",
    "\n",
    "# start the MICE training\n",
    "imputed_training1=mice(x_train_outliers_imputation.values)\n",
    "\n",
    "array_sum = np.sum(imputed_training1) #https://www.adamsmith.haus/python/answers/how-to-check-for-nan-elements-in-a-numpy-array-in-python\n",
    "Trainset1 = np.isnan(array_sum)\n",
    "\n",
    "Trainset1 #Checking for NaN elements in a NumPy array returns True if the array contains any NaN elements and False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ce2b65-56bf-4ffd-9413-7ea368948c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2.By Using Outlier Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f3a51f-bfa7-4490-b664-09882cf4b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from impyute.imputation.cs import mice\n",
    "\n",
    "# start the MICE training\n",
    "imputed_training2=mice(df_outliers.values)\n",
    "\n",
    "array_sum = np.sum(imputed_training2) #https://www.adamsmith.haus/python/answers/how-to-check-for-nan-elements-in-a-numpy-array-in-python\n",
    "Trainset2 = np.isnan(array_sum)\n",
    "\n",
    "Trainset2 #Checking for NaN elements in a NumPy array returns True if the array contains any NaN elements and False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4558728-7e18-46ab-9d4a-688fed8f0f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe80908-6a6b-44b1-a7c4-d95bbc2aeeb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
