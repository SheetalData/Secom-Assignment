{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07549054-0c13-48a4-bac3-bf44cbef0eac",
   "metadata": {},
   "source": [
    "# Step 1:Loading and Merging The dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45f6bdca-24b9-41f7-97c0-ee712a4d3cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature1  feature2   feature3   feature4  feature5  feature6  feature7  \\\n",
      "0      3030.93   2564.00  2187.7333  1411.1265    1.3602     100.0   97.6133   \n",
      "1      3095.78   2465.14  2230.4222  1463.6606    0.8294     100.0  102.3433   \n",
      "2      2932.61   2559.94  2186.4111  1698.0172    1.5102     100.0   95.4878   \n",
      "3      2988.72   2479.90  2199.0333   909.7926    1.3204     100.0  104.2367   \n",
      "4      3032.24   2502.87  2233.3667  1326.5200    1.5334     100.0  100.3967   \n",
      "...        ...       ...        ...        ...       ...       ...       ...   \n",
      "1562   2899.41   2464.36  2179.7333  3085.3781    1.4843     100.0   82.2467   \n",
      "1563   3052.31   2522.55  2198.5667  1124.6595    0.8763     100.0   98.4689   \n",
      "1564   2978.81   2379.78  2206.3000  1110.4967    0.8236     100.0   99.4122   \n",
      "1565   2894.92   2532.01  2177.0333  1183.7287    1.5726     100.0   98.7978   \n",
      "1566   2944.92   2450.76  2195.4444  2914.1792    1.5978     100.0   85.1011   \n",
      "\n",
      "      feature8  feature9  feature10  ...  feature583  feature584  feature585  \\\n",
      "0       0.1242    1.5005     0.0162  ...      0.5005      0.0118      0.0035   \n",
      "1       0.1247    1.4966    -0.0005  ...      0.5019      0.0223      0.0055   \n",
      "2       0.1241    1.4436     0.0041  ...      0.4958      0.0157      0.0039   \n",
      "3       0.1217    1.4882    -0.0124  ...      0.4990      0.0103      0.0025   \n",
      "4       0.1235    1.5031    -0.0031  ...      0.4800      0.4766      0.1045   \n",
      "...        ...       ...        ...  ...         ...         ...         ...   \n",
      "1562    0.1248    1.3424    -0.0045  ...      0.4988      0.0143      0.0039   \n",
      "1563    0.1205    1.4333    -0.0061  ...      0.4975      0.0131      0.0036   \n",
      "1564    0.1208       NaN        NaN  ...      0.4987      0.0153      0.0041   \n",
      "1565    0.1213    1.4622    -0.0072  ...      0.5004      0.0178      0.0038   \n",
      "1566    0.1235       NaN        NaN  ...      0.4987      0.0181      0.0040   \n",
      "\n",
      "      feature586  feature587  feature588  feature589  feature590  Result  \\\n",
      "0         2.3630         NaN         NaN         NaN         NaN      -1   \n",
      "1         4.4447      0.0096      0.0201      0.0060    208.2045      -1   \n",
      "2         3.1745      0.0584      0.0484      0.0148     82.8602       1   \n",
      "3         2.0544      0.0202      0.0149      0.0044     73.8432      -1   \n",
      "4        99.3032      0.0202      0.0149      0.0044     73.8432      -1   \n",
      "...          ...         ...         ...         ...         ...     ...   \n",
      "1562      2.8669      0.0068      0.0138      0.0047    203.1720      -1   \n",
      "1563      2.6238      0.0068      0.0138      0.0047    203.1720      -1   \n",
      "1564      3.0590      0.0197      0.0086      0.0025     43.5231      -1   \n",
      "1565      3.5662      0.0262      0.0245      0.0075     93.4941      -1   \n",
      "1566      3.6275      0.0117      0.0162      0.0045    137.7844      -1   \n",
      "\n",
      "                    Date  \n",
      "0    2008-07-19 11:55:00  \n",
      "1    2008-07-19 12:32:00  \n",
      "2    2008-07-19 13:17:00  \n",
      "3    2008-07-19 14:43:00  \n",
      "4    2008-07-19 15:22:00  \n",
      "...                  ...  \n",
      "1562 2008-10-16 15:13:00  \n",
      "1563 2008-10-16 20:49:00  \n",
      "1564 2008-10-17 05:26:00  \n",
      "1565 2008-10-17 06:01:00  \n",
      "1566 2008-10-17 06:07:00  \n",
      "\n",
      "[1567 rows x 592 columns]\n",
      "shape of x: (1567, 590)\n",
      "shape of y: (1567, 1)\n",
      "shape of x_train:  (1096, 590)\n",
      "shape of x_test:  (471, 590)\n",
      "shape of y_train:  (1096, 1)\n",
      "shape of y_test:  (471, 1)\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "#Load the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import shapiro\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "\n",
    "#Load the datasets\n",
    "\n",
    "url1 ='https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data'\n",
    "names = [\"feature\" + str(x) for x in range(1, 591)]\n",
    "df1 = pd.read_csv(url1,sep=\" \", names=names, na_values = \"NaN\",header=None)\n",
    "df1.head()\n",
    "\n",
    "url2 ='https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom_labels.data'\n",
    "df2 = pd.read_csv(url2,sep=\" \",names = [\"Result\",\"Date\"])\n",
    "#df2.columns =['Pass/Fail','Date']\n",
    "df2.head()\n",
    "\n",
    "\n",
    "\n",
    "#Convertion of Date into Datetime from Object(String) data types\n",
    "df2['Date'] = pd.to_datetime(df2['Date'])\n",
    "df2.dtypes\n",
    "\n",
    "\n",
    "\n",
    "#Joinig TWO df1 and df2 Dataframe naming SECOM\n",
    "Secom = pd.concat([df1,df2],axis = 1)\n",
    "print(Secom)\n",
    "\n",
    "\n",
    "\n",
    "#We consider datetime donot have an important effect of whether a test fails or not.so dropping this column.\n",
    "Secom = Secom.drop(['Date'],axis=1)\n",
    "  \n",
    "    \n",
    "    \n",
    "# establish target and features of the manufacturing data\n",
    "# set the target to the encoded manufacturing outcome column\n",
    "\n",
    "y = Secom[['Result']]\n",
    "\n",
    "\n",
    "\n",
    "# set the features as the rest of the dataset after dropping the features that are no\n",
    "\n",
    "x = Secom.drop(['Result'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# getting the shapes of new data sets x and y\n",
    "\n",
    "print(\"shape of x:\", x.shape)\n",
    "print(\"shape of y:\", y.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d30639-e01d-4ee2-afc1-88116e2f1772",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step 2: Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ab301-88d1-47a0-9eed-d68918745b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data\n",
    "#Since according to dataset's description, target values are highly umbalanced, so we split it in a stratified fashion.\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 1,stratify = y)\n",
    "\n",
    "\n",
    "\n",
    "# getting the counts\n",
    "\n",
    "print(\"shape of x_train: \", x_train.shape)\n",
    "print(\"shape of x_test: \", x_test.shape)\n",
    "print(\"shape of y_train: \", y_train.shape)\n",
    "print(\"shape of y_test: \", y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa5822-b791-4229-9b02-c193dc0f770a",
   "metadata": {},
   "source": [
    "# Step3: Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afafb777-e762-41cb-bcfe-0625c7470ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REMOVING FEATURES HAVING MISSING VALUE RATIO MORE THAN 50%.\n",
    "\n",
    "def percentna(dataframe, threshold):\n",
    "    columns = dataframe.columns[(dataframe.isnull().sum()/len(dataframe))>threshold]\n",
    "    return columns.tolist()\n",
    "na_columns = percentna(x_train, 0.5)\n",
    "len(na_columns)\n",
    "x_train_dn = x_train.drop(na_columns, axis=1)\n",
    "x_train_dn.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#REMOVING COLUMNS WITH UNIQUE VALUES(Low Variance)\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "var_thres=VarianceThreshold(threshold=0)\n",
    "var_thres.fit(x_train_dn)\n",
    "constant_columns = [column for column in x_train_dn.columns\n",
    "                    if column not in x_train_dn.columns[var_thres.get_support()]]\n",
    "print(len(constant_columns))\n",
    "x_train_lv = x_train_dn.drop(constant_columns,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#Dropping the Columns in test data also\n",
    "\n",
    "x_test_drop = x_test.copy()\n",
    "x_test_drop = x_test_drop.drop(na_columns, axis=1)\n",
    "x_test_drop = x_test_drop.drop(constant_columns,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#OUTLIER IMPUTATION\n",
    "\n",
    "def outliers(feat):\n",
    " upper_limit = feat.mean() + 3*feat.std()\n",
    " lower_limit = feat.mean() - 3*feat.std()\n",
    "\n",
    " feat = np.where(\n",
    "    feat >upper_limit,\n",
    "    upper_limit,\n",
    "    np.where(\n",
    "       feat <lower_limit,\n",
    "        lower_limit,\n",
    "        feat ))\n",
    " return feat\n",
    "\n",
    "x_train_outliers_imputation =x_train_lv.copy()\n",
    "for column in x_train_outliers_imputation:\n",
    "  x_train_outliers_imputation[column] = outliers(x_train_outliers_imputation[column])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dc154d-96c7-4acb-ad5c-0d61d279a1bd",
   "metadata": {},
   "source": [
    "# Step4: Missing value imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7048edb-219d-4ef2-9343-1d7c300380de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using KNN Imputation Method\n",
    "\n",
    "numColumns = x_train_outliers_imputation.select_dtypes(include=np.number).columns.tolist();\n",
    "# initialize imputer\n",
    "imputer = KNNImputer()\n",
    "# fit the imputer on X_train. pass only numeric columns.\n",
    "imputer.fit(x_train_outliers_imputation[numColumns])\n",
    "# transform the data using the fitted imputer\n",
    "X_train_knn_impute1 = imputer.transform(x_train_outliers_imputation[numColumns])\n",
    "X_test_knn_impute1 = imputer.transform(x_test[numColumns])\n",
    "# put the output into DataFrame. remember to pass columns used in fit/transform\n",
    "X_train_knn_impute1 = pd.DataFrame(X_train_knn_impute1, columns=numColumns)\n",
    "X_test_knn_impute1 = imputer.transform(x_test[numColumns])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a0decd-f051-496f-a00a-44a800853903",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Step5: Feature reduction using Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abf9c39-1ae1-4317-bb86-78b2ac0f447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install boruta\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=1, n_estimators=1000, max_depth=5)\n",
    "boruta_selector = BorutaPy(rfc, n_estimators='auto', verbose=2, random_state=1)\n",
    "boruta_selector.fit(np.array(X_train_knn_impute1), np.array(y_train)) \n",
    "\n",
    "# Ranking of Boruta\n",
    "\n",
    "print(\"Ranking: \",boruta_selector.ranking_)          \n",
    "print(\"No. of significant features: \", boruta_selector.n_features_) \n",
    "\n",
    "selected_rf_features = pd.DataFrame({'Feature':list(X_train_knn_impute1.columns),\n",
    "                                       'Ranking':boruta_selector.ranking_})\n",
    "selected_rf_features.sort_values(by='Ranking').head(30)\n",
    "\n",
    "# Using the BorutaPy object to transform the features in the dataset.\n",
    "\n",
    "X_Filtered_train = boruta_selector.transform(np.array(X_train_knn_impute1))\n",
    "\n",
    "X_Filtered_test = boruta_selector.transform(np.array(X_test_knn_impute1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f42b7a-3e97-4657-afad-f88abebaf635",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Checking Accuracy using RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7835b96-c6e3-4532-8446-47b105e93acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "#from sklearn.metrics import scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "classifiers = [['RandomForest :',RandomForestClassifier()]]\n",
    "\n",
    "for name,classifier in classifiers:\n",
    "    clf=classifier.fit(X_Filtered_train,y_train)\n",
    "    y_pred=classifier.predict(X_Filtered_test)\n",
    "    print(f'\\n {name} \\n')\n",
    "    print(f'Training Score for {name}  {clf.score(X_Filtered_train,y_train) * 100:.2f}' )\n",
    "    print(f'Testing Score for {name} {clf.score(X_Filtered_test,y_test) * 100:.2f}' )\n",
    "    print(f'Classification report  \\n {classification_report(y_test,y_pred)}' )\n",
    "    print(f'Confusion matrix  \\n {confusion_matrix(y_test,y_pred)}' )\n",
    "    print(f'ROC AUC  : {roc_auc_score(y_test,y_pred)}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97e3c05-1f2e-4f31-9935-44d82e9c687f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using Estimator to check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b75940-a4d3-4425-8db7-6410d8ac835c",
   "metadata": {},
   "source": [
    "The performance of RandomForestRegressor on the full cleaned dataset is then compared the performance on the altered datasets with the  missing values imputed using different techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6631a7c-1373-4ce7-a5eb-044d913a1263",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# To use the experimental IterativeImputer, we need to explicitly ask for it:\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "N_SPLITS = 5\n",
    "regressor = RandomForestRegressor(random_state=0)\n",
    "\n",
    "\n",
    "def get_scores_for_imputer(imputer, X_missing, y_missing):\n",
    "    estimator = make_pipeline(imputer, regressor)\n",
    "    impute_scores = cross_val_score(\n",
    "        estimator, X_missing, y_missing, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    )\n",
    "    return impute_scores\n",
    "\n",
    "\n",
    "x_labels = []\n",
    "\n",
    "mses = np.zeros(4)\n",
    "stds = np.zeros(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d962bbe1-845d-4a31-bb25-a0cef74aacea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full data score\n",
    "def get_full_score(X_full, y_full):\n",
    "    full_scores = cross_val_score(\n",
    "        regressor, X_full, y_full, scoring=\"neg_mean_squared_error\", cv=N_SPLITS\n",
    "    )\n",
    "    return full_scores.mean(), full_scores.std()\n",
    "\n",
    "\n",
    "mses[0] ,stds[0] = get_full_score(X_Filtered_train, y_train)\n",
    "\n",
    "x_labels.append(\"Full data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c8ec82-6db6-4c88-ac34-33ce0325698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN Imputation Score\n",
    "def get_impute_knn_score(X_missing, y_missing):\n",
    "    imputer = KNNImputer(missing_values=np.nan, add_indicator=True)\n",
    "    knn_impute_scores = get_scores_for_imputer(imputer, X_missing, y_missing)\n",
    "    return knn_impute_scores.mean(), knn_impute_scores.std()\n",
    "\n",
    "\n",
    "mses[1] ,stds[1] = get_impute_knn_score(x_train_outliers_imputation,  y_train)\n",
    "x_labels.append(\"KNN Imputation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db8d4d13-fca6-4863-ba52-632cba3444a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Imputation score\n",
    "def get_impute_mean(X_missing, y_missing):\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\", add_indicator=True)\n",
    "    mean_impute_scores = get_scores_for_imputer(imputer, X_missing, y_missing)\n",
    "    return mean_impute_scores.mean(), mean_impute_scores.std()\n",
    "\n",
    "mses[2] ,stds[2] = get_impute_mean(x_train_outliers_imputation,  y_train)\n",
    "x_labels.append(\"Mean Imputation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97c25998-52ba-4c48-ab25-67018705e137",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MICE Imputation Score\n",
    "def get_impute_iterative(X_missing, y_missing):\n",
    "    imputer = IterativeImputer(missing_values=np.nan,add_indicator=True,random_state=0,n_nearest_features=3,max_iter=1,sample_posterior=True)\n",
    "    iterative_impute_scores = get_scores_for_imputer(imputer, X_missing, y_missing)\n",
    "    return iterative_impute_scores.mean(), iterative_impute_scores.std()\n",
    "\n",
    "\n",
    "mses[3], stds[3] = get_impute_iterative(x_train_outliers_imputation,  y_train)\n",
    "\n",
    "x_labels.append(\"Iterative Imputation\")\n",
    "\n",
    "mses = mses * -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd3373ed-cafb-4c2d-909d-5b2d9ce49e80",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of ticklabels (6).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1748/3783872503.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0max2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MSE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0max2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvert_yaxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0max2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_yticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\_api\\deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    469\u001b[0m                 \u001b[1;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[1;32m--> 471\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36m_set_ticklabels\u001b[1;34m(self, labels, fontdict, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1793\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1795\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ticklabels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1797\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_ticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mticks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axis.py\u001b[0m in \u001b[0;36mset_ticklabels\u001b[1;34m(self, ticklabels, minor, **kwargs)\u001b[0m\n\u001b[0;32m   1714\u001b[0m             \u001b[1;31m# remove all tick labels, so only error for > 0 ticklabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticklabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1716\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   1717\u001b[0m                     \u001b[1;34m\"The number of FixedLocator locations\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1718\u001b[0m                     \u001b[1;34mf\" ({len(locator.locs)}), usually from a call to\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The number of FixedLocator locations (4), usually from a call to set_ticks, does not match the number of ticklabels (6)."
     ]
    }
   ],
   "source": [
    "#Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_bars = len(mses)\n",
    "xval = np.arange(n_bars)\n",
    "\n",
    "colors = [\"r\", \"g\",\"b\",\"orange\"]\n",
    "\n",
    "# plot california dataset results\n",
    "plt.figure(figsize=(20, 12))\n",
    "ax2 = plt.subplot(122)\n",
    "for j in xval:\n",
    "    ax2.barh(\n",
    "        j,\n",
    "        mses[j],\n",
    "        xerr=stds[j],\n",
    "        color=colors[j],\n",
    "        alpha=0.6,\n",
    "        align=\"center\",\n",
    "    )\n",
    "\n",
    "ax2.set_title(\"Imputation Techniques\")\n",
    "ax2.set_yticks(xval)\n",
    "ax2.set_xlabel(\"MSE\")\n",
    "ax2.invert_yaxis()\n",
    "ax2.set_yticklabels(x_labels)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d295ca-89a4-47fe-a57c-adc0584c99bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
