{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b10f8c0-8bbc-4d37-826f-9d839232b2c5",
   "metadata": {},
   "source": [
    "### Missing value imputation using KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a514c-4eff-4340-a749-9effb1f6ecaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84e2e26c-cf06-4ca5-83ee-d154a87dcc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      feature1  feature2   feature3   feature4  feature5  feature6  feature7  \\\n",
      "0      3030.93   2564.00  2187.7333  1411.1265    1.3602     100.0   97.6133   \n",
      "1      3095.78   2465.14  2230.4222  1463.6606    0.8294     100.0  102.3433   \n",
      "2      2932.61   2559.94  2186.4111  1698.0172    1.5102     100.0   95.4878   \n",
      "3      2988.72   2479.90  2199.0333   909.7926    1.3204     100.0  104.2367   \n",
      "4      3032.24   2502.87  2233.3667  1326.5200    1.5334     100.0  100.3967   \n",
      "...        ...       ...        ...        ...       ...       ...       ...   \n",
      "1562   2899.41   2464.36  2179.7333  3085.3781    1.4843     100.0   82.2467   \n",
      "1563   3052.31   2522.55  2198.5667  1124.6595    0.8763     100.0   98.4689   \n",
      "1564   2978.81   2379.78  2206.3000  1110.4967    0.8236     100.0   99.4122   \n",
      "1565   2894.92   2532.01  2177.0333  1183.7287    1.5726     100.0   98.7978   \n",
      "1566   2944.92   2450.76  2195.4444  2914.1792    1.5978     100.0   85.1011   \n",
      "\n",
      "      feature8  feature9  feature10  ...  feature583  feature584  feature585  \\\n",
      "0       0.1242    1.5005     0.0162  ...      0.5005      0.0118      0.0035   \n",
      "1       0.1247    1.4966    -0.0005  ...      0.5019      0.0223      0.0055   \n",
      "2       0.1241    1.4436     0.0041  ...      0.4958      0.0157      0.0039   \n",
      "3       0.1217    1.4882    -0.0124  ...      0.4990      0.0103      0.0025   \n",
      "4       0.1235    1.5031    -0.0031  ...      0.4800      0.4766      0.1045   \n",
      "...        ...       ...        ...  ...         ...         ...         ...   \n",
      "1562    0.1248    1.3424    -0.0045  ...      0.4988      0.0143      0.0039   \n",
      "1563    0.1205    1.4333    -0.0061  ...      0.4975      0.0131      0.0036   \n",
      "1564    0.1208       NaN        NaN  ...      0.4987      0.0153      0.0041   \n",
      "1565    0.1213    1.4622    -0.0072  ...      0.5004      0.0178      0.0038   \n",
      "1566    0.1235       NaN        NaN  ...      0.4987      0.0181      0.0040   \n",
      "\n",
      "      feature586  feature587  feature588  feature589  feature590  Result  \\\n",
      "0         2.3630         NaN         NaN         NaN         NaN      -1   \n",
      "1         4.4447      0.0096      0.0201      0.0060    208.2045      -1   \n",
      "2         3.1745      0.0584      0.0484      0.0148     82.8602       1   \n",
      "3         2.0544      0.0202      0.0149      0.0044     73.8432      -1   \n",
      "4        99.3032      0.0202      0.0149      0.0044     73.8432      -1   \n",
      "...          ...         ...         ...         ...         ...     ...   \n",
      "1562      2.8669      0.0068      0.0138      0.0047    203.1720      -1   \n",
      "1563      2.6238      0.0068      0.0138      0.0047    203.1720      -1   \n",
      "1564      3.0590      0.0197      0.0086      0.0025     43.5231      -1   \n",
      "1565      3.5662      0.0262      0.0245      0.0075     93.4941      -1   \n",
      "1566      3.6275      0.0117      0.0162      0.0045    137.7844      -1   \n",
      "\n",
      "                    Date  \n",
      "0    2008-07-19 11:55:00  \n",
      "1    2008-07-19 12:32:00  \n",
      "2    2008-07-19 13:17:00  \n",
      "3    2008-07-19 14:43:00  \n",
      "4    2008-07-19 15:22:00  \n",
      "...                  ...  \n",
      "1562 2008-10-16 15:13:00  \n",
      "1563 2008-10-16 20:49:00  \n",
      "1564 2008-10-17 05:26:00  \n",
      "1565 2008-10-17 06:01:00  \n",
      "1566 2008-10-17 06:07:00  \n",
      "\n",
      "[1567 rows x 592 columns]\n",
      "shape of x: (1567, 590)\n",
      "shape of y: (1567, 1)\n",
      "shape of x_train:  (1096, 590)\n",
      "shape of x_test:  (471, 590)\n",
      "shape of y_train:  (1096, 1)\n",
      "shape of y_test:  (471, 1)\n",
      "116\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import missingno as msno\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import shapiro\n",
    "# imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "url1 ='https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data'\n",
    "names = [\"feature\" + str(x) for x in range(1, 591)]\n",
    "df1 = pd.read_csv(url1,sep=\" \", names=names, na_values = \"NaN\",header=None)\n",
    "df1.head()\n",
    "\n",
    "url2 ='https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom_labels.data'\n",
    "df2 = pd.read_csv(url2,sep=\" \",names = [\"Result\",\"Date\"])\n",
    "\n",
    "#df2.columns =['Pass/Fail','Date']\n",
    "df2.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Convertion of Date into Datetime from Object(String) data types\n",
    "df2['Date'] = pd.to_datetime(df2['Date'])\n",
    "df2.dtypes\n",
    "\n",
    "\n",
    "\n",
    "#Joinig TWO df1 and df2 Dataframe naming SECOM\n",
    "Secom = pd.concat([df1,df2],axis = 1)\n",
    "print(Secom)\n",
    "\n",
    "Secom = Secom.drop(['Date'],axis=1)\n",
    "                   \n",
    "# establish target and features of the manufacturing data\n",
    "# set the target to the encoded manufacturing outcome column\n",
    "y = Secom[['Result']]\n",
    "# set the features as the rest of the dataset after dropping the features that are no\n",
    "x = Secom.drop(['Result'], axis=1)\n",
    "\n",
    "# getting the shapes of new data sets x and y\n",
    "print(\"shape of x:\", x.shape)\n",
    "print(\"shape of y:\", y.shape)\n",
    "\n",
    "#Splitting data\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 1,stratify = y)\n",
    "\n",
    "\n",
    "\n",
    "# getting the counts\n",
    "print(\"shape of x_train: \", x_train.shape)\n",
    "print(\"shape of x_test: \", x_test.shape)\n",
    "print(\"shape of y_train: \", y_train.shape)\n",
    "print(\"shape of y_test: \", y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Removing features having Missing ratio more than 50%\n",
    "\n",
    "\n",
    "def percentna(dataframe, threshold):\n",
    "    columns = dataframe.columns[(dataframe.isnull().sum()/len(dataframe))>threshold]\n",
    "    return columns.tolist()\n",
    "\n",
    " \n",
    "\n",
    "na_columns = percentna(x_train, 0.5)\n",
    "len(na_columns)\n",
    "x_train_dn = x_train.drop(na_columns, axis=1)\n",
    "x_train_dn.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Low Variance Filter\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "var_thres=VarianceThreshold(threshold=0)\n",
    "var_thres.fit(x_train_dn)\n",
    "\n",
    " \n",
    "\n",
    "constant_columns = [column for column in x_train_dn.columns\n",
    "                    if column not in x_train_dn.columns[var_thres.get_support()]]\n",
    "\n",
    "\n",
    "print(len(constant_columns))\n",
    "\n",
    "x_train_lv = x_train_dn.drop(constant_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32aea087",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_drop = x_test.copy()\n",
    "\n",
    "x_test_drop = x_test_drop.drop(na_columns, axis=1)\n",
    "\n",
    "x_test_drop = x_test_drop.drop(constant_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce9550b9-6202-4d2f-bb2b-3dfc0e4e0163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(feat):\n",
    " upper_limit = feat.mean() + 3*feat.std()\n",
    " lower_limit = feat.mean() - 3*feat.std()\n",
    "\n",
    " feat = np.where(\n",
    "    feat >upper_limit,\n",
    "    upper_limit,\n",
    "    np.where(\n",
    "       feat <lower_limit,\n",
    "        lower_limit,\n",
    "        feat ))\n",
    " return feat\n",
    "\n",
    "x_train_outliers_imputation =x_train_lv.copy()\n",
    "for column in x_train_outliers_imputation:\n",
    "  x_train_outliers_imputation[column] = outliers(x_train_outliers_imputation[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d95be323-b48c-401d-b3ed-5076e1c3746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "numColumns = x_train_outliers_imputation.select_dtypes(include=np.number).columns.tolist();\n",
    "#numColumns2 = x_test.select_dtypes(include=np.number).columns.tolist();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db2a7873-325b-40f4-b045-80596e969b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize imputer\n",
    "imputer = KNNImputer()\n",
    "\n",
    "\n",
    "\n",
    "# fit the imputer on X_train. pass only numeric columns.\n",
    "imputer.fit(x_train_outliers_imputation[numColumns])\n",
    "\n",
    "\n",
    "\n",
    "# transform the data using the fitted imputer\n",
    "X_train_knn_impute1 = imputer.transform(x_train_outliers_imputation[numColumns])\n",
    "X_test_knn_impute1 = imputer.transform(x_test_drop[numColumns])\n",
    "\n",
    "\n",
    "\n",
    "# put the output into DataFrame. remember to pass columns used in fit/transform\n",
    "X_train_knn_impute1 = pd.DataFrame(X_train_knn_impute1, columns=numColumns)\n",
    "X_test_knn_impute1 = pd.DataFrame(X_test_knn_impute1, columns=numColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d92a30-2d26-4039-9ce4-1df13a39cca7",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a00f48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix \n",
      " [[ 0.02653982 -0.00419749 -0.00050406 ... -0.00058656 -0.00072725\n",
      "  -0.00042327]\n",
      " [-0.00419749  0.02585938  0.00135255 ...  0.00060217  0.00022807\n",
      "   0.00107126]\n",
      " [-0.00050406  0.00135255  0.02529192 ... -0.00134907 -0.00118887\n",
      "  -0.00121662]\n",
      " ...\n",
      " [-0.00058656  0.00060217 -0.00134907 ...  0.04180563  0.04087559\n",
      "   0.01890297]\n",
      " [-0.00072725  0.00022807 -0.00118887 ...  0.04087559  0.04238368\n",
      "   0.01892012]\n",
      " [-0.00042327  0.00107126 -0.00121662 ...  0.01890297  0.01892012\n",
      "   0.04448709]]\n",
      "Cumulative Variance Explained [  4.62898836+0.0000000e+00j   7.78413099+0.0000000e+00j\n",
      "  10.74959777+0.0000000e+00j  13.32406358+0.0000000e+00j\n",
      "  15.55107643+0.0000000e+00j  17.65434876+0.0000000e+00j\n",
      "  19.58272142+0.0000000e+00j  21.41662848+0.0000000e+00j\n",
      "  23.16893582+0.0000000e+00j  24.88189773+0.0000000e+00j\n",
      "  26.55655017+0.0000000e+00j  28.20791653+0.0000000e+00j\n",
      "  29.73886726+0.0000000e+00j  31.14212347+0.0000000e+00j\n",
      "  32.49039156+0.0000000e+00j  33.78542803+0.0000000e+00j\n",
      "  35.06548266+0.0000000e+00j  36.31440196+0.0000000e+00j\n",
      "  37.53195873+0.0000000e+00j  38.6504444 +0.0000000e+00j\n",
      "  39.75183842+0.0000000e+00j  40.83361923+0.0000000e+00j\n",
      "  41.88628786+0.0000000e+00j  42.93512851+0.0000000e+00j\n",
      "  43.94218354+0.0000000e+00j  44.92327995+0.0000000e+00j\n",
      "  45.88881688+0.0000000e+00j  46.8416025 +0.0000000e+00j\n",
      "  47.76706215+0.0000000e+00j  48.67729888+0.0000000e+00j\n",
      "  49.58010116+0.0000000e+00j  50.44865831+0.0000000e+00j\n",
      "  51.31591395+0.0000000e+00j  52.15154212+0.0000000e+00j\n",
      "  52.98194169+0.0000000e+00j  53.78950865+0.0000000e+00j\n",
      "  54.58621497+0.0000000e+00j  55.37828763+0.0000000e+00j\n",
      "  56.14177792+0.0000000e+00j  56.9001868 +0.0000000e+00j\n",
      "  57.65552809+0.0000000e+00j  58.397793  +0.0000000e+00j\n",
      "  59.1295876 +0.0000000e+00j  59.85100219+0.0000000e+00j\n",
      "  60.55791566+0.0000000e+00j  61.25104951+0.0000000e+00j\n",
      "  61.93006093+0.0000000e+00j  62.59330621+0.0000000e+00j\n",
      "  63.24427788+0.0000000e+00j  63.88520679+0.0000000e+00j\n",
      "  64.51815981+0.0000000e+00j  65.14392511+0.0000000e+00j\n",
      "  65.75223413+0.0000000e+00j  66.35687666+0.0000000e+00j\n",
      "  66.94728795+0.0000000e+00j  67.53021112+0.0000000e+00j\n",
      "  68.10120735+0.0000000e+00j  68.65817322+0.0000000e+00j\n",
      "  69.20216506+0.0000000e+00j  69.74167286+0.0000000e+00j\n",
      "  70.27040152+0.0000000e+00j  70.78556225+0.0000000e+00j\n",
      "  71.29169946+0.0000000e+00j  71.78913847+0.0000000e+00j\n",
      "  72.2841224 +0.0000000e+00j  72.76953726+0.0000000e+00j\n",
      "  73.24135119+0.0000000e+00j  73.70678818+0.0000000e+00j\n",
      "  74.16356956+0.0000000e+00j  74.61872659+0.0000000e+00j\n",
      "  75.06701425+0.0000000e+00j  75.49331468+0.0000000e+00j\n",
      "  75.91370348+0.0000000e+00j  76.33238714+0.0000000e+00j\n",
      "  76.73946399+0.0000000e+00j  77.13833056+0.0000000e+00j\n",
      "  77.53509882+0.0000000e+00j  77.93008564+0.0000000e+00j\n",
      "  78.32002312+0.0000000e+00j  78.69394702+0.0000000e+00j\n",
      "  79.06440926+0.0000000e+00j  79.43340723+0.0000000e+00j\n",
      "  79.79352067+0.0000000e+00j  80.15081007+0.0000000e+00j\n",
      "  80.50188305+0.0000000e+00j  80.84718314+0.0000000e+00j\n",
      "  81.18988507+0.0000000e+00j  81.52395945+0.0000000e+00j\n",
      "  81.85433771+0.0000000e+00j  82.17767064+0.0000000e+00j\n",
      "  82.49361789+0.0000000e+00j  82.8079246 +0.0000000e+00j\n",
      "  83.11139015+0.0000000e+00j  83.41213524+0.0000000e+00j\n",
      "  83.70670327+0.0000000e+00j  83.99919394+0.0000000e+00j\n",
      "  84.28914085+0.0000000e+00j  84.57449743+0.0000000e+00j\n",
      "  84.85390773+0.0000000e+00j  85.12985619+0.0000000e+00j\n",
      "  85.40408741+0.0000000e+00j  85.67454695+0.0000000e+00j\n",
      "  85.94036393+0.0000000e+00j  86.20384302+0.0000000e+00j\n",
      "  86.46169188+0.0000000e+00j  86.7123235 +0.0000000e+00j\n",
      "  86.96082173+0.0000000e+00j  87.20146839+0.0000000e+00j\n",
      "  87.44064683+0.0000000e+00j  87.67886828+0.0000000e+00j\n",
      "  87.91050507+0.0000000e+00j  88.14118377+0.0000000e+00j\n",
      "  88.36716744+0.0000000e+00j  88.59000006+0.0000000e+00j\n",
      "  88.81038929+0.0000000e+00j  89.02822155+0.0000000e+00j\n",
      "  89.24020185+0.0000000e+00j  89.45046107+0.0000000e+00j\n",
      "  89.65564933+0.0000000e+00j  89.85873552+0.0000000e+00j\n",
      "  90.0603966 +0.0000000e+00j  90.25794476+0.0000000e+00j\n",
      "  90.45391763+0.0000000e+00j  90.64258237+0.0000000e+00j\n",
      "  90.8300673 +0.0000000e+00j  91.01528462+0.0000000e+00j\n",
      "  91.19872065+0.0000000e+00j  91.37838215+0.0000000e+00j\n",
      "  91.55603074+0.0000000e+00j  91.73189529+0.0000000e+00j\n",
      "  91.90536921+0.0000000e+00j  92.07734567+0.0000000e+00j\n",
      "  92.24688798+0.0000000e+00j  92.41249333+0.0000000e+00j\n",
      "  92.57793022+0.0000000e+00j  92.73583643+0.0000000e+00j\n",
      "  92.89124369+0.0000000e+00j  93.0447648 +0.0000000e+00j\n",
      "  93.19698727+0.0000000e+00j  93.34726884+0.0000000e+00j\n",
      "  93.49489538+0.0000000e+00j  93.64031105+0.0000000e+00j\n",
      "  93.78271116+0.0000000e+00j  93.92150173+0.0000000e+00j\n",
      "  94.05909752+0.0000000e+00j  94.19337453+0.0000000e+00j\n",
      "  94.32547469+0.0000000e+00j  94.45545185+0.0000000e+00j\n",
      "  94.58431178+0.0000000e+00j  94.71091835+0.0000000e+00j\n",
      "  94.83357857+0.0000000e+00j  94.95441759+0.0000000e+00j\n",
      "  95.07302313+0.0000000e+00j  95.18838029+0.0000000e+00j\n",
      "  95.30063558+0.0000000e+00j  95.4112907 +0.0000000e+00j\n",
      "  95.52030424+0.0000000e+00j  95.62840401+0.0000000e+00j\n",
      "  95.73390128+0.0000000e+00j  95.8354681 +0.0000000e+00j\n",
      "  95.9359475 +0.0000000e+00j  96.03469102+0.0000000e+00j\n",
      "  96.1314273 +0.0000000e+00j  96.22695071+0.0000000e+00j\n",
      "  96.32190003+0.0000000e+00j  96.41425461+0.0000000e+00j\n",
      "  96.50438018+0.0000000e+00j  96.59333549+0.0000000e+00j\n",
      "  96.67984565+0.0000000e+00j  96.76472511+0.0000000e+00j\n",
      "  96.84813041+0.0000000e+00j  96.93071208+0.0000000e+00j\n",
      "  97.01242078+0.0000000e+00j  97.093346  +0.0000000e+00j\n",
      "  97.17075952+0.0000000e+00j  97.24569364+0.0000000e+00j\n",
      "  97.31871411+0.0000000e+00j  97.38956334+0.0000000e+00j\n",
      "  97.45709425+0.0000000e+00j  97.52419431+0.0000000e+00j\n",
      "  97.58984405+0.0000000e+00j  97.6533018 +0.0000000e+00j\n",
      "  97.71616137+0.0000000e+00j  97.77672028+0.0000000e+00j\n",
      "  97.83599666+0.0000000e+00j  97.89442595+0.0000000e+00j\n",
      "  97.95277493+0.0000000e+00j  98.00864555+0.0000000e+00j\n",
      "  98.06276305+0.0000000e+00j  98.11448017+0.0000000e+00j\n",
      "  98.1643388 +0.0000000e+00j  98.21326833+0.0000000e+00j\n",
      "  98.26102557+0.0000000e+00j  98.30509307+0.0000000e+00j\n",
      "  98.34874707+0.0000000e+00j  98.39199771+0.0000000e+00j\n",
      "  98.43480747+0.0000000e+00j  98.47678804+0.0000000e+00j\n",
      "  98.51811708+0.0000000e+00j  98.55785074+0.0000000e+00j\n",
      "  98.59552111+0.0000000e+00j  98.63189825+0.0000000e+00j\n",
      "  98.6677583 +0.0000000e+00j  98.7026059 +0.0000000e+00j\n",
      "  98.73595847+0.0000000e+00j  98.76836745+0.0000000e+00j\n",
      "  98.8007003 +0.0000000e+00j  98.83212893+0.0000000e+00j\n",
      "  98.8621079 +0.0000000e+00j  98.89120329+0.0000000e+00j\n",
      "  98.91958952+0.0000000e+00j  98.94705801+0.0000000e+00j\n",
      "  98.97394979+0.0000000e+00j  99.00034349+0.0000000e+00j\n",
      "  99.02600933+0.0000000e+00j  99.05130246+0.0000000e+00j\n",
      "  99.07582202+0.0000000e+00j  99.09924811+0.0000000e+00j\n",
      "  99.12139762+0.0000000e+00j  99.14275894+0.0000000e+00j\n",
      "  99.16388386+0.0000000e+00j  99.18425337+0.0000000e+00j\n",
      "  99.2037204 +0.0000000e+00j  99.22274296+0.0000000e+00j\n",
      "  99.24100182+0.0000000e+00j  99.25904807+0.0000000e+00j\n",
      "  99.27697681+0.0000000e+00j  99.29434541+0.0000000e+00j\n",
      "  99.31134126+0.0000000e+00j  99.32794799+0.0000000e+00j\n",
      "  99.34402422+0.0000000e+00j  99.3598786 +0.0000000e+00j\n",
      "  99.37524669+0.0000000e+00j  99.3902732 +0.0000000e+00j\n",
      "  99.40445487+0.0000000e+00j  99.41834297+0.0000000e+00j\n",
      "  99.43185563+0.0000000e+00j  99.44504713+0.0000000e+00j\n",
      "  99.45804218+0.0000000e+00j  99.47084334+0.0000000e+00j\n",
      "  99.48338152+0.0000000e+00j  99.49562374+0.0000000e+00j\n",
      "  99.5075658 +0.0000000e+00j  99.51906056+0.0000000e+00j\n",
      "  99.53043236+0.0000000e+00j  99.54140774+0.0000000e+00j\n",
      "  99.55214338+0.0000000e+00j  99.56262877+0.0000000e+00j\n",
      "  99.57288682+0.0000000e+00j  99.58295343+0.0000000e+00j\n",
      "  99.59288976+0.0000000e+00j  99.60265375+0.0000000e+00j\n",
      "  99.61225985+0.0000000e+00j  99.62169374+0.0000000e+00j\n",
      "  99.63090783+0.0000000e+00j  99.63986942+0.0000000e+00j\n",
      "  99.64850979+0.0000000e+00j  99.65702042+0.0000000e+00j\n",
      "  99.6654631 +0.0000000e+00j  99.67389256+0.0000000e+00j\n",
      "  99.68211856+0.0000000e+00j  99.69004447+0.0000000e+00j\n",
      "  99.6978797 +0.0000000e+00j  99.70554206+0.0000000e+00j\n",
      "  99.71305267+0.0000000e+00j  99.7204391 +0.0000000e+00j\n",
      "  99.72776285+0.0000000e+00j  99.7349009 +0.0000000e+00j\n",
      "  99.74181841+0.0000000e+00j  99.74850096+0.0000000e+00j\n",
      "  99.75514556+0.0000000e+00j  99.76176298+0.0000000e+00j\n",
      "  99.76815194+0.0000000e+00j  99.77438006+0.0000000e+00j\n",
      "  99.78055442+0.0000000e+00j  99.78662461+0.0000000e+00j\n",
      "  99.79263336+0.0000000e+00j  99.79861546+0.0000000e+00j\n",
      "  99.80442192+0.0000000e+00j  99.81000108+0.0000000e+00j\n",
      "  99.8154667 +0.0000000e+00j  99.82081946+0.0000000e+00j\n",
      "  99.8258976 +0.0000000e+00j  99.83096488+0.0000000e+00j\n",
      "  99.83599193+0.0000000e+00j  99.84092633+0.0000000e+00j\n",
      "  99.84567667+0.0000000e+00j  99.85036862+0.0000000e+00j\n",
      "  99.85500094+0.0000000e+00j  99.85956119+0.0000000e+00j\n",
      "  99.86399474+0.0000000e+00j  99.86837172+0.0000000e+00j\n",
      "  99.87262007+0.0000000e+00j  99.87683269+0.0000000e+00j\n",
      "  99.8809808 +0.0000000e+00j  99.88502356+0.0000000e+00j\n",
      "  99.8890026 +0.0000000e+00j  99.89287452+0.0000000e+00j\n",
      "  99.89658152+0.0000000e+00j  99.90027015+0.0000000e+00j\n",
      "  99.90377455+0.0000000e+00j  99.90717951+0.0000000e+00j\n",
      "  99.91055852+0.0000000e+00j  99.91389139+0.0000000e+00j\n",
      "  99.91710925+0.0000000e+00j  99.92019291+0.0000000e+00j\n",
      "  99.92324188+0.0000000e+00j  99.92613906+0.0000000e+00j\n",
      "  99.92898697+0.0000000e+00j  99.93179182+0.0000000e+00j\n",
      "  99.93452905+0.0000000e+00j  99.93708663+0.0000000e+00j\n",
      "  99.93950019+0.0000000e+00j  99.9418116 +0.0000000e+00j\n",
      "  99.94410352+0.0000000e+00j  99.9463167 +0.0000000e+00j\n",
      "  99.94842677+0.0000000e+00j  99.95045737+0.0000000e+00j\n",
      "  99.95243665+0.0000000e+00j  99.95437745+0.0000000e+00j\n",
      "  99.95625092+0.0000000e+00j  99.95808643+0.0000000e+00j\n",
      "  99.95981665+0.0000000e+00j  99.96148152+0.0000000e+00j\n",
      "  99.9631378 +0.0000000e+00j  99.96472852+0.0000000e+00j\n",
      "  99.96626865+0.0000000e+00j  99.96775512+0.0000000e+00j\n",
      "  99.96921028+0.0000000e+00j  99.97055094+0.0000000e+00j\n",
      "  99.97185709+0.0000000e+00j  99.97310062+0.0000000e+00j\n",
      "  99.97431168+0.0000000e+00j  99.97545741+0.0000000e+00j\n",
      "  99.97655546+0.0000000e+00j  99.97760502+0.0000000e+00j\n",
      "  99.97860798+0.0000000e+00j  99.97959556+0.0000000e+00j\n",
      "  99.98051652+0.0000000e+00j  99.98142564+0.0000000e+00j\n",
      "  99.98227156+0.0000000e+00j  99.98309934+0.0000000e+00j\n",
      "  99.98390086+0.0000000e+00j  99.98468142+0.0000000e+00j\n",
      "  99.98543663+0.0000000e+00j  99.98618938+0.0000000e+00j\n",
      "  99.98689598+0.0000000e+00j  99.98756507+0.0000000e+00j\n",
      "  99.98821416+0.0000000e+00j  99.98884797+0.0000000e+00j\n",
      "  99.98946647+0.0000000e+00j  99.99005774+0.0000000e+00j\n",
      "  99.99062553+0.0000000e+00j  99.9911533 +0.0000000e+00j\n",
      "  99.99165358+0.0000000e+00j  99.99213616+0.0000000e+00j\n",
      "  99.99258269+0.0000000e+00j  99.99301468+0.0000000e+00j\n",
      "  99.99341773+0.0000000e+00j  99.99380804+0.0000000e+00j\n",
      "  99.9941461 +0.0000000e+00j  99.99447377+0.0000000e+00j\n",
      "  99.99477859+0.0000000e+00j  99.99507601+0.0000000e+00j\n",
      "  99.99534164+0.0000000e+00j  99.99560372+0.0000000e+00j\n",
      "  99.99584906+0.0000000e+00j  99.99607322+0.0000000e+00j\n",
      "  99.99628768+0.0000000e+00j  99.99648259+0.0000000e+00j\n",
      "  99.99666777+0.0000000e+00j  99.99684996+0.0000000e+00j\n",
      "  99.99702719+0.0000000e+00j  99.99719441+0.0000000e+00j\n",
      "  99.99735755+0.0000000e+00j  99.99751471+0.0000000e+00j\n",
      "  99.9976634 +0.0000000e+00j  99.99780398+0.0000000e+00j\n",
      "  99.99793949+0.0000000e+00j  99.99807137+0.0000000e+00j\n",
      "  99.99819359+0.0000000e+00j  99.99830303+0.0000000e+00j\n",
      "  99.99840482+0.0000000e+00j  99.99850523+0.0000000e+00j\n",
      "  99.99860257+0.0000000e+00j  99.99869342+0.0000000e+00j\n",
      "  99.99878189+0.0000000e+00j  99.99886933+0.0000000e+00j\n",
      "  99.99894666+0.0000000e+00j  99.99902168+0.0000000e+00j\n",
      "  99.99909418+0.0000000e+00j  99.99916592+0.0000000e+00j\n",
      "  99.9992341 +0.0000000e+00j  99.99929608+0.0000000e+00j\n",
      "  99.9993565 +0.0000000e+00j  99.99941164+0.0000000e+00j\n",
      "  99.99946472+0.0000000e+00j  99.99950352+0.0000000e+00j\n",
      "  99.9995402 +0.0000000e+00j  99.99957221+0.0000000e+00j\n",
      "  99.99960259+0.0000000e+00j  99.99963209+0.0000000e+00j\n",
      "  99.99965953+0.0000000e+00j  99.99968608+0.0000000e+00j\n",
      "  99.9997117 +0.0000000e+00j  99.99973641+0.0000000e+00j\n",
      "  99.99976054+0.0000000e+00j  99.99978312+0.0000000e+00j\n",
      "  99.99980316+0.0000000e+00j  99.99982205+0.0000000e+00j\n",
      "  99.99983982+0.0000000e+00j  99.99985671+0.0000000e+00j\n",
      "  99.99987286+0.0000000e+00j  99.99988655+0.0000000e+00j\n",
      "  99.99989989+0.0000000e+00j  99.99991001+0.0000000e+00j\n",
      "  99.99991857+0.0000000e+00j  99.99992644+0.0000000e+00j\n",
      "  99.99993347+0.0000000e+00j  99.99994017+0.0000000e+00j\n",
      "  99.99994676+0.0000000e+00j  99.99995309+0.0000000e+00j\n",
      "  99.99995845+0.0000000e+00j  99.99996295+0.0000000e+00j\n",
      "  99.99996721+0.0000000e+00j  99.99997129+0.0000000e+00j\n",
      "  99.99997506+0.0000000e+00j  99.99997868+0.0000000e+00j\n",
      "  99.99998208+0.0000000e+00j  99.99998519+0.0000000e+00j\n",
      "  99.99998821+0.0000000e+00j  99.99999113+0.0000000e+00j\n",
      "  99.99999367+0.0000000e+00j  99.99999607+0.0000000e+00j\n",
      "  99.99999786+0.0000000e+00j  99.99999882+0.0000000e+00j\n",
      "  99.99999948+0.0000000e+00j  99.99999982+0.0000000e+00j\n",
      "  99.9999999 +0.0000000e+00j  99.99999994+0.0000000e+00j\n",
      "  99.99999998+0.0000000e+00j  99.99999999+0.0000000e+00j\n",
      " 100.        +0.0000000e+00j 100.        +0.0000000e+00j\n",
      " 100.        +0.0000000e+00j 100.        +0.0000000e+00j\n",
      " 100.        +0.0000000e+00j 100.        +0.0000000e+00j\n",
      " 100.        +5.5404331e-18j 100.        +0.0000000e+00j]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "col=list(X_train_knn_impute1.columns)\n",
    "col1=list(X_test_knn_impute1.columns)\n",
    "scaler = MinMaxScaler()\n",
    "scaled_feature = scaler.fit_transform(X_train_knn_impute1)\n",
    "scaled_feature = pd.DataFrame(scaled_feature,columns=col)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "# Creating a covariance matrix\n",
    "\n",
    "cov_matrix = np.cov(scaled_feature.T)\n",
    "print('Covariance Matrix \\n', cov_matrix)\n",
    "      \n",
    "#perform an eigendecomposition on the covariance matrix:\n",
    "\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_matrix)  \n",
    "\n",
    "tot = sum(eig_vals)\n",
    "var_exp = [( i /tot ) * 100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print(\"Cumulative Variance Explained\", cum_var_exp)\n",
    "pca = PCA(n_components=scaled_feature.shape[1],random_state=1).fit(scaled_feature.values)\n",
    "a = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "\n",
    "i = 0\n",
    "while a[i] < 0.9:\n",
    "    i = i+1\n",
    "f'Number of dimensions needed to capture 90%% of variance:{i}'\n",
    "\n",
    "\n",
    "# PCA with reduced number of components\n",
    "\n",
    "pca = PCA(n_components=i,random_state=1)\n",
    "pca.fit(scaled_feature)\n",
    "#print(pca.components_)\n",
    "\n",
    "pca_df= pd.DataFrame(pca.fit_transform(scaled_feature))\n",
    "from sklearn.decomposition import PCA\n",
    "# create a PCA object\n",
    "pca = PCA(n_components = i)# extracted features we want to end up within our new dataset(2).\n",
    "# Apply the above object to our training dataset using the fit method.\n",
    "X_train = pca.fit_transform(X_train_knn_impute1)\n",
    "# Apply the PCA object to the test set only to transform this set\n",
    "X_test = pca.fit_transform(X_test_knn_impute1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4a27e9-cbab-4eec-a61b-254774b4437e",
   "metadata": {},
   "source": [
    "## Evaluation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a17cf979-1498-4d1e-b1c8-e8357dfca6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RandomForest : \n",
      "\n",
      "Training Score for RandomForest :  99.91\n",
      "Testing Score for RandomForest : 93.42\n",
      "Classification report  \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.93      1.00      0.97       440\n",
      "           1       0.00      0.00      0.00        31\n",
      "\n",
      "    accuracy                           0.93       471\n",
      "   macro avg       0.47      0.50      0.48       471\n",
      "weighted avg       0.87      0.93      0.90       471\n",
      "\n",
      "Confusion matrix  \n",
      " [[440   0]\n",
      " [ 31   0]]\n",
      "ROC AUC  : 0.5\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "#from sklearn.metrics import scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "classifiers = [['RandomForest :',RandomForestClassifier()]]\n",
    "\n",
    "for name,classifier in classifiers:\n",
    "    clf=classifier.fit(X_train,y_train)\n",
    "    y_pred=classifier.predict(X_test)\n",
    "    print(f'\\n {name} \\n')\n",
    "    print(f'Training Score for {name}  {clf.score(X_train,y_train) * 100:.2f}' )\n",
    "    print(f'Testing Score for {name} {clf.score(X_test,y_test) * 100:.2f}' )\n",
    "    print(f'Classification report  \\n {classification_report(y_test,y_pred)}' )\n",
    "    print(f'Confusion matrix  \\n {confusion_matrix(y_test,y_pred)}' )\n",
    "    print(f'ROC AUC  : {roc_auc_score(y_test,y_pred)}' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e500ec-f7ca-4ce9-a538-69e930fbe290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "364be49c34f555e5dc4e2a5bead572c972738deaa840ade2ee170fdfb470b0ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
