{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8ef4b1-1175-4248-8eb2-ed600b8a4376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75f617e-97aa-4296-b1ef-8bea620e23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "from pandas_profiling import ProfileReport\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import missingno as msno\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import shapiro\n",
    "# imputer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "url1 ='https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom.data'\n",
    "names = [\"feature\" + str(x) for x in range(1, 591)]\n",
    "df1 = pd.read_csv(url1,sep=\" \", names=names, na_values = \"NaN\",header=None)\n",
    "df1.head()\n",
    "\n",
    "url2 ='https://archive.ics.uci.edu/ml/machine-learning-databases/secom/secom_labels.data'\n",
    "df2 = pd.read_csv(url2,sep=\" \",names = [\"Result\",\"Date\"])\n",
    "\n",
    "#df2.columns =['Pass/Fail','Date']\n",
    "df2.head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Convertion of Date into Datetime from Object(String) data types\n",
    "df2['Date'] = pd.to_datetime(df2['Date'])\n",
    "df2.dtypes\n",
    "\n",
    "\n",
    "\n",
    "#Joinig TWO df1 and df2 Dataframe naming SECOM\n",
    "Secom = pd.concat([df1,df2],axis = 1)\n",
    "print(Secom)\n",
    "\n",
    "Secom = Secom.drop(['Date'],axis=1)\n",
    "                   \n",
    "# establish target and features of the manufacturing data\n",
    "# set the target to the encoded manufacturing outcome column\n",
    "y = Secom[['Result']]\n",
    "# set the features as the rest of the dataset after dropping the features that are no\n",
    "x = Secom.drop(['Result'], axis=1)\n",
    "\n",
    "# getting the shapes of new data sets x and y\n",
    "print(\"shape of x:\", x.shape)\n",
    "print(\"shape of y:\", y.shape)\n",
    "\n",
    "#Splitting data\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 1,stratify = y)\n",
    "\n",
    "\n",
    "\n",
    "# getting the counts\n",
    "print(\"shape of x_train: \", x_train.shape)\n",
    "print(\"shape of x_test: \", x_test.shape)\n",
    "print(\"shape of y_train: \", y_train.shape)\n",
    "print(\"shape of y_test: \", y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Removing features having Missing ratio more than 50%\n",
    "\n",
    "\n",
    "def percentna(dataframe, threshold):\n",
    "    columns = dataframe.columns[(dataframe.isnull().sum()/len(dataframe))>threshold]\n",
    "    return columns.tolist()\n",
    "\n",
    " \n",
    "\n",
    "na_columns = percentna(x_train, 0.5)\n",
    "len(na_columns)\n",
    "x_train_dn = x_train.drop(na_columns, axis=1)\n",
    "x_train_dn.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Low Variance Filter\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "var_thres=VarianceThreshold(threshold=0)\n",
    "var_thres.fit(x_train_dn)\n",
    "\n",
    " \n",
    "\n",
    "constant_columns = [column for column in x_train_dn.columns\n",
    "                    if column not in x_train_dn.columns[var_thres.get_support()]]\n",
    "\n",
    "\n",
    "print(len(constant_columns))\n",
    "\n",
    "x_train_lv = x_train_dn.drop(constant_columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f8bdff-1287-4d98-93c9-9ec359a6de53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(feat):\n",
    " upper_limit = feat.mean() + 3*feat.std()\n",
    " lower_limit = feat.mean() - 3*feat.std()\n",
    "\n",
    " feat = np.where(\n",
    "    feat >upper_limit,\n",
    "    upper_limit,\n",
    "    np.where(\n",
    "       feat <lower_limit,\n",
    "        lower_limit,\n",
    "        feat ))\n",
    " return feat\n",
    "\n",
    "x_train_outliers_imputation =x_train_lv.copy()\n",
    "for column in x_train_outliers_imputation:\n",
    "  x_train_outliers_imputation[column] = outliers(x_train_outliers_imputation[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecf87cb-f27f-4136-84a4-3f7bda1f0239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest information available\n",
    "x_train_LastFill1 = x_train_outliers_imputation.copy()\n",
    "x_train_LastFill1.fillna(method='ffill', inplace=True)\n",
    "x_train_LastFill1.fillna(method='bfill', inplace=True)\n",
    "x_train_LastFill1\n",
    "\n",
    "x_train_LastFill1.isna().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8606d17e-b846-49b3-b04f-3ab43a4d218e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_LastFill1 = x_test.copy()\n",
    "x_test_LastFill1.fillna(method='ffill', inplace=True)\n",
    "x_test_LastFill1.fillna(method='bfill', inplace=True)\n",
    "x_test_LastFill1\n",
    "\n",
    "x_test_LastFill1.isna().sum().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6d819-1c09-490c-b0ee-297ef040a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BORUTA\n",
    "#REFERENCE: https://github.com/bnsreenu/python_for_microscopists/blob/master/198_Boruta_feature_selection_breast_cancer.py\n",
    "#pip install boruta\n",
    " \n",
    "#Standarize train data for BORUTA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train_std = sc.fit_transform(x_train_LastFill1)\n",
    "x_test_std = sc.transform(x_test_LastFill1)\n",
    " \n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from boruta import BorutaPy\n",
    " \n",
    "# load y_train as an array\n",
    " \n",
    "y = y_train.values\n",
    "y = y.ravel()\n",
    " \n",
    "# define random forest classifier, with utilising all cores and\n",
    "# sampling in proportion to y labels\n",
    "rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    " \n",
    "# define Boruta feature selection method\n",
    "feat_selector = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=1)\n",
    " \n",
    "# find all relevant features \n",
    "feat_selector.fit(x_train_std, y)\n",
    " \n",
    "# check selected features \n",
    "feat_selector.support_\n",
    " \n",
    "# check ranking of features\n",
    "feat_selector.ranking_\n",
    " \n",
    "# call transform() on X to filter it down to selected features\n",
    "X_filtered = feat_selector.transform(x_train_std)\n",
    " \n",
    "import numpy as np\n",
    "feature_names = np.array(Secom.columns)\n",
    " \n",
    "# Ranked features greater than threshold\n",
    "feature_ranks = list(zip(feature_names, \n",
    " feat_selector.ranking_, \n",
    " feat_selector.support_))\n",
    " \n",
    "# print the results\n",
    "for feat in feature_ranks:\n",
    " print('Feature: {:<30} Rank: {}, Keep: {}'.format(feat[0], feat[1], feat[2]))\n",
    " \n",
    "#Now use the subset of features to fit XGBoost model on training data\n",
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBClassifier()\n",
    " \n",
    "xgb_model.fit(X_filtered, y_train)\n",
    " \n",
    "#Now predict on test data using the trained model. \n",
    " \n",
    "#First apply feature selector transform to make sure same features are selected from test data\n",
    "X_test_filtered = feat_selector.transform(x_test_std)\n",
    "prediction_xgb = xgb_model.predict(X_test_filtered)\n",
    " \n",
    "#Print overall accuracy\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction_xgb))\n",
    " \n",
    "#Confusion Matrix - verify accuracy of each class\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, prediction_xgb)\n",
    "#print(cm)\n",
    "sns.heatmap(cm, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
